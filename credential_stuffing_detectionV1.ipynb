{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93975a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce3dbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion d'attaques : 0.08\n"
     ]
    }
   ],
   "source": [
    "RND = 42\n",
    "np.random.seed(RND)\n",
    "random.seed(RND)\n",
    "\n",
    "# -------------------------\n",
    "# 1) Fonctions utilitaires\n",
    "# -------------------------\n",
    "def generate_ip_pool(n_public=2000, n_private=200):\n",
    "    # Crée une liste d'IP publiques et privées (simples)\n",
    "    pool = []\n",
    "    # IP privées (10., 192.168., 172.16-31)\n",
    "    for _ in range(n_private):\n",
    "        pool.append(f\"10.{random.randint(0,255)}.{random.randint(0,255)}.{random.randint(1,254)}\")\n",
    "    # IP publiques (simples variations)\n",
    "    for _ in range(n_public):\n",
    "        pool.append(f\"{random.randint(1,223)}.{random.randint(0,255)}.{random.randint(0,255)}.{random.randint(1,254)}\")\n",
    "    return pool\n",
    "\n",
    "def random_timestamp(start_days=90):\n",
    "    # timestamp aléatoire dans les start_days derniers jours\n",
    "    base = datetime.now()\n",
    "    delta = timedelta(days=random.randint(0, start_days), hours=random.randint(0,23), minutes=random.randint(0,59))\n",
    "    return base - delta\n",
    "\n",
    "# -------------------------\n",
    "# 2) Génération du dataset\n",
    "# -------------------------\n",
    "def generate_realistic_dataset(n_records=20000, ip_pool=None, attacker_ip_frac=0.06):\n",
    "    if ip_pool is None:\n",
    "        ip_pool = generate_ip_pool()\n",
    "    n_ips = len(ip_pool)\n",
    "    # Choisir quelques IP qui seront \"attaquantes\" récurrentes (mais pas toutes les sessions d'une IP seront attaques)\n",
    "    n_attacker_ips = max(1, int(n_ips * attacker_ip_frac))\n",
    "    attacker_ips = set(np.random.choice(ip_pool, size=n_attacker_ips, replace=False))\n",
    "    \n",
    "    rows = []\n",
    "    for i in range(n_records):\n",
    "        # Choisir IP (avec plus de chance de réutiliser IP attaquante si c'est une IP d'attaque)\n",
    "        if random.random() < 0.02 and len(attacker_ips)>0:  # 2% de prob de créer un \"burst\" explicite\n",
    "            ip = random.choice(list(attacker_ips))\n",
    "        else:\n",
    "            ip = random.choice(ip_pool)\n",
    "        \n",
    "        # Baseline attempt counts (légitimes ont souvent 1-5 tentatives, attaques 3-150 mais avec chevauchement)\n",
    "        is_attacker_ip_prior = 1 if ip in attacker_ips else 0\n",
    "        attempts_from_ip = int(np.clip(np.random.poisson(1 + 3*is_attacker_ip_prior) + np.random.choice([0,1,2], p=[0.7,0.2,0.1]), 1, 200))\n",
    "        \n",
    "        # failed_attempts : légitime peut échouer, attaque aussi ; on ajoute chevauchement\n",
    "        # échantillonnage selon Beta-Binomial style (approx)\n",
    "        fail_ratio_base = np.random.beta(1 + 2*is_attacker_ip_prior, 2 + 1*(1-is_attacker_ip_prior))\n",
    "        failed_attempts = int(np.clip(np.round(fail_ratio_base * attempts_from_ip + np.random.randint(0,2)), 0, attempts_from_ip))\n",
    "        \n",
    "        login_success = attempts_from_ip - failed_attempts\n",
    "        # login duration: attaques très rapides mais avec overlap\n",
    "        if random.random() < 0.25*is_attacker_ip_prior:\n",
    "            login_duration_seconds = np.random.uniform(0.05, 3.0) * max(1, attempts_from_ip/10)\n",
    "        else:\n",
    "            # sessions utilisateurs : durée plus variable\n",
    "            login_duration_seconds = np.random.exponential(scale=3.0) + np.random.uniform(0.2, 6.0)\n",
    "            # petite corrélation : plus d'essais -> durée légèrement plus grande\n",
    "            login_duration_seconds += attempts_from_ip * np.random.uniform(0.01, 0.2)\n",
    "        login_duration_seconds = float(np.clip(login_duration_seconds, 0.05, 600))\n",
    "        \n",
    "        # request_size_bytes : overlap but attacks might be a bit larger on average\n",
    "        request_size_bytes = int(np.clip(np.random.normal(800 + 400*is_attacker_ip_prior, 300), 100, 10000))\n",
    "        \n",
    "        # requests_per_minute: poisson with overlap\n",
    "        lam = 2 + 8*is_attacker_ip_prior + np.random.uniform(-1,2)\n",
    "        requests_per_minute = int(np.clip(np.random.poisson(max(1, lam)), 0, 5000))\n",
    "        \n",
    "        # Timestamp\n",
    "        ts = random_timestamp(start_days=120)\n",
    "        \n",
    "        rows.append({\n",
    "            'timestamp': ts,\n",
    "            'ip_address': ip,\n",
    "            'login_success': login_success,\n",
    "            'attempts_from_ip': attempts_from_ip,\n",
    "            'failed_attempts': failed_attempts,\n",
    "            'login_duration_seconds': login_duration_seconds,\n",
    "            'request_size_bytes': request_size_bytes,\n",
    "            'requests_per_minute': requests_per_minute\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    # On mélange pour éviter tout ordre biaisé\n",
    "    df = df.sample(frac=1, random_state=RND).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Générer dataset\n",
    "ip_pool = generate_ip_pool(n_public=1800, n_private=200)\n",
    "df = generate_realistic_dataset(n_records=20000, ip_pool=ip_pool, attacker_ip_frac=0.06)\n",
    "\n",
    "# -------------------------\n",
    "# 3) Création d'un label réaliste (probabiliste)\n",
    "# -------------------------\n",
    "# On calcule un score d'attaque latent à partir des features (sans \"fuite explicite\")\n",
    "def compute_attack_score(row):\n",
    "    # Normaliser approximativement via heuristiques (on ne veut pas utiliser stats du dataset complet pour éviter fuite)\n",
    "    a = row['attempts_from_ip']\n",
    "    f = row['failed_attempts']\n",
    "    rpm = row['requests_per_minute']\n",
    "    rs = row['request_size_bytes']\n",
    "    avg_time = row['login_duration_seconds'] / max(1, a)\n",
    "    \n",
    "    # composantes : échecs relatifs, fréquence de requêtes, essais totaux, taille des requêtes, temps moyen\n",
    "    comp_fail = (f / max(1, a))        # 0..1\n",
    "    comp_attempts = np.log1p(a) / np.log1p(200)  # 0..1 approx\n",
    "    comp_rpm = np.log1p(rpm) / np.log1p(500)     # 0..1 approx\n",
    "    comp_size = (rs - 100) / (10000 - 100)       # 0..1 approx\n",
    "    comp_time = 1.0 - np.tanh(avg_time / 10.0)   # attaques tendent à avoir avg_time faible -> comp_time proche 1\n",
    "    \n",
    "    # pondérations arbitraires mais réalistes + bruit\n",
    "    score = 0.35*comp_fail + 0.25*comp_rpm + 0.2*comp_attempts + 0.1*comp_size + 0.1*comp_time\n",
    "    score += np.random.normal(0, 0.07)  # bruit\n",
    "    return np.clip(score, 0.0, 1.0)\n",
    "\n",
    "df['attack_score'] = df.apply(compute_attack_score, axis=1)\n",
    "\n",
    "# transformer score en label probabiliste (seuil dynamique pour obtenir ~6-10% d'attaques)\n",
    "threshold = 0.62\n",
    "df['is_credential_stuffing'] = (df['attack_score'] > threshold).astype(int)\n",
    "\n",
    "# Ajuster proportion si besoin (pour simuler dataset réaliste)\n",
    "# Si proportion trop faible/élevée, on ajuste threshold pour atteindre cible (facultatif)\n",
    "target_frac = 0.08\n",
    "current_frac = df['is_credential_stuffing'].mean()\n",
    "if abs(current_frac - target_frac) > 0.01:\n",
    "    # trouver threshold qui donne target_frac approximatif\n",
    "    thr = np.percentile(df['attack_score'], 100*(1-target_frac))\n",
    "    df['is_credential_stuffing'] = (df['attack_score'] >= thr).astype(int)\n",
    "\n",
    "print(\"Proportion d'attaques :\", df['is_credential_stuffing'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a96d6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (20000, 10)\n",
      "Credential stuffing cases: 1600\n",
      "=== 10 premières lignes ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>login_success</th>\n",
       "      <th>attempts_from_ip</th>\n",
       "      <th>failed_attempts</th>\n",
       "      <th>login_duration_seconds</th>\n",
       "      <th>request_size_bytes</th>\n",
       "      <th>requests_per_minute</th>\n",
       "      <th>attack_score</th>\n",
       "      <th>is_credential_stuffing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-13 12:45:27</td>\n",
       "      <td>47.38.148.235</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.213630</td>\n",
       "      <td>991</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-04 17:43:23</td>\n",
       "      <td>158.36.203.7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.326295</td>\n",
       "      <td>957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-17 19:15:26</td>\n",
       "      <td>10.54.223.19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.403439</td>\n",
       "      <td>286</td>\n",
       "      <td>3</td>\n",
       "      <td>0.572005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-03 05:17:22</td>\n",
       "      <td>142.111.240.238</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.093761</td>\n",
       "      <td>1259</td>\n",
       "      <td>4</td>\n",
       "      <td>0.520577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-21 05:54:28</td>\n",
       "      <td>113.88.251.211</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.978925</td>\n",
       "      <td>609</td>\n",
       "      <td>5</td>\n",
       "      <td>0.219976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-08-29 20:49:27</td>\n",
       "      <td>125.37.144.166</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.939954</td>\n",
       "      <td>486</td>\n",
       "      <td>4</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-08-31 01:09:27</td>\n",
       "      <td>55.44.21.104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.869387</td>\n",
       "      <td>988</td>\n",
       "      <td>3</td>\n",
       "      <td>0.446720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-09-23 16:46:23</td>\n",
       "      <td>151.39.111.216</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12.341943</td>\n",
       "      <td>842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-08-05 02:29:30</td>\n",
       "      <td>115.200.186.176</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.378385</td>\n",
       "      <td>812</td>\n",
       "      <td>6</td>\n",
       "      <td>0.196255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-09-15 13:25:25</td>\n",
       "      <td>28.143.92.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.186468</td>\n",
       "      <td>975</td>\n",
       "      <td>4</td>\n",
       "      <td>0.097881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp       ip_address  login_success  attempts_from_ip  \\\n",
       "0  2025-08-13 12:45:27    47.38.148.235              1                 2   \n",
       "1  2025-08-04 17:43:23     158.36.203.7              6                 6   \n",
       "2  2025-08-17 19:15:26     10.54.223.19              0                 1   \n",
       "3  2025-08-03 05:17:22  142.111.240.238              0                 1   \n",
       "4  2025-09-21 05:54:28   113.88.251.211              1                 1   \n",
       "5  2025-08-29 20:49:27   125.37.144.166              0                 2   \n",
       "6  2025-08-31 01:09:27     55.44.21.104              1                 2   \n",
       "7  2025-09-23 16:46:23   151.39.111.216              1                 2   \n",
       "8  2025-08-05 02:29:30  115.200.186.176              1                 1   \n",
       "9  2025-09-15 13:25:25     28.143.92.99              2                 2   \n",
       "\n",
       "   failed_attempts  login_duration_seconds  request_size_bytes  \\\n",
       "0                1                4.213630                 991   \n",
       "1                0                5.326295                 957   \n",
       "2                1                8.403439                 286   \n",
       "3                1                5.093761                1259   \n",
       "4                0                6.978925                 609   \n",
       "5                2                5.939954                 486   \n",
       "6                1                6.869387                 988   \n",
       "7                1               12.341943                 842   \n",
       "8                0                4.378385                 812   \n",
       "9                0                4.186468                 975   \n",
       "\n",
       "   requests_per_minute  attack_score  is_credential_stuffing  \n",
       "0                    1      0.364206                       0  \n",
       "1                    1      0.152904                       0  \n",
       "2                    3      0.572005                       1  \n",
       "3                    4      0.520577                       0  \n",
       "4                    5      0.219976                       0  \n",
       "5                    4      0.503610                       0  \n",
       "6                    3      0.446720                       0  \n",
       "7                    1      0.292187                       0  \n",
       "8                    6      0.196255                       0  \n",
       "9                    4      0.097881                       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_records = 20000\n",
    "ip_pool = generate_ip_pool(n_public=1800, n_private=200)\n",
    "\n",
    "# Appel de la nouvelle fonction\n",
    "df = generate_realistic_dataset(n_records=n_records, ip_pool=ip_pool, attacker_ip_frac=0.06)\n",
    "\n",
    "# Création des labels\n",
    "df['attack_score'] = df.apply(compute_attack_score, axis=1)\n",
    "threshold = 0.62\n",
    "df['is_credential_stuffing'] = (df['attack_score'] > threshold).astype(int)\n",
    "\n",
    "# Ajustement facultatif pour atteindre proportion cible\n",
    "target_frac = 0.08\n",
    "current_frac = df['is_credential_stuffing'].mean()\n",
    "if abs(current_frac - target_frac) > 0.01:\n",
    "    thr = np.percentile(df['attack_score'], 100*(1-target_frac))\n",
    "    df['is_credential_stuffing'] = (df['attack_score'] >= thr).astype(int)\n",
    "\n",
    "# Format du timestamp\n",
    "df['timestamp'] = df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Infos\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Credential stuffing cases: {df['is_credential_stuffing'].sum()}\")\n",
    "print(\"=== 10 premières lignes ===\")\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc19fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to 'credential_stuffing_detection.csv'\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"credential_stuffing_detection.csv\", index=False)\n",
    "print(\"Dataset saved to 'credential_stuffing_detection.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f205f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rates and derived features\n",
    "df['failed_attempt_ratio'] = df['failed_attempts'] / df['attempts_from_ip']\n",
    "df['success_ratio'] = df['login_success'] / df['attempts_from_ip']\n",
    "df['avg_login_time'] = df['login_duration_seconds'] / df['attempts_from_ip']\n",
    "\n",
    "# IP privée indicateur (détection simple)\n",
    "df['is_private_ip'] = df['ip_address'].str.startswith(('10.', '172.', '192.168')).astype(int)\n",
    "\n",
    "# Timestamp features\n",
    "df['hour'] = pd.to_datetime(df['timestamp']).dt.hour\n",
    "df['day_of_week'] = pd.to_datetime(df['timestamp']).dt.dayofweek\n",
    "\n",
    "# Features finales sélectionnées\n",
    "features = [\n",
    "    'attempts_from_ip', 'failed_attempts', 'login_duration_seconds',\n",
    "    'request_size_bytes', 'requests_per_minute',\n",
    "    'failed_attempt_ratio', 'success_ratio', 'avg_login_time',\n",
    "    'is_private_ip', 'hour', 'day_of_week'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2af36fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer inf / nan si présents (sécurité)\n",
    "df[features] = df[features].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# -------------------------\n",
    "# 5) Train/Test & Modèles\n",
    "# -------------------------\n",
    "X = df[features]\n",
    "y = df['is_credential_stuffing']\n",
    "\n",
    "# Split stratifié\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=RND, stratify=y)\n",
    "\n",
    "# Scale uniquement pour la régression logistique\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f79aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest (GridSearch léger)\n",
    "rf = RandomForestClassifier(random_state=RND)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "}\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_best = rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14be5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=RND, max_iter=1000)\n",
    "lr_params = {'C': [0.1, 1.0, 5.0]}\n",
    "lr_grid = GridSearchCV(lr, lr_params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "lr_best = lr_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a6ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (RBF kernel) + GridSearch\n",
    "# -------------------------\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=RND, class_weight='balanced')\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 5],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "svm_grid = GridSearchCV(svm, svm_params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "svm_best = svm_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b836671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN + GridSearch\n",
    "# -------------------------\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn_grid = GridSearchCV(knn, knn_params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "knn_grid.fit(X_train_scaled, y_train)\n",
    "knn_best = knn_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a658394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Random Forest ====\n",
      "Confusion Matrix:\n",
      "[[3644   36]\n",
      " [ 246   74]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.937     0.990     0.963      3680\n",
      "           1      0.673     0.231     0.344       320\n",
      "\n",
      "    accuracy                          0.929      4000\n",
      "   macro avg      0.805     0.611     0.653      4000\n",
      "weighted avg      0.916     0.929     0.913      4000\n",
      "\n",
      "ROC-AUC Score: 0.8953\n",
      "\n",
      "\n",
      "==== Logistic Regression (scaled) ====\n",
      "Confusion Matrix:\n",
      "[[3644   36]\n",
      " [ 248   72]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.936     0.990     0.962      3680\n",
      "           1      0.667     0.225     0.336       320\n",
      "\n",
      "    accuracy                          0.929      4000\n",
      "   macro avg      0.801     0.608     0.649      4000\n",
      "weighted avg      0.915     0.929     0.912      4000\n",
      "\n",
      "ROC-AUC Score: 0.8989\n",
      "\n",
      "\n",
      "==== SVM (RBF) ====\n",
      "Confusion Matrix:\n",
      "[[2536 1144]\n",
      " [  20  300]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.689     0.813      3680\n",
      "           1      0.208     0.938     0.340       320\n",
      "\n",
      "    accuracy                          0.709      4000\n",
      "   macro avg      0.600     0.813     0.577      4000\n",
      "weighted avg      0.929     0.709     0.775      4000\n",
      "\n",
      "ROC-AUC Score: 0.8825\n",
      "\n",
      "\n",
      "==== KNN ====\n",
      "Confusion Matrix:\n",
      "[[3610   70]\n",
      " [ 245   75]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.936     0.981     0.958      3680\n",
      "           1      0.517     0.234     0.323       320\n",
      "\n",
      "    accuracy                          0.921      4000\n",
      "   macro avg      0.727     0.608     0.640      4000\n",
      "weighted avg      0.903     0.921     0.907      4000\n",
      "\n",
      "ROC-AUC Score: 0.7978\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6) Évaluation\n",
    "# -------------------------\n",
    "def evaluate_model(model, X_eval, y_eval, name=\"Model\"):\n",
    "    y_pred = model.predict(X_eval)\n",
    "    y_proba = model.predict_proba(X_eval)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "    print(f\"==== {name} ====\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_eval, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_eval, y_pred, digits=3))\n",
    "    if y_proba is not None:\n",
    "        print(\"ROC-AUC Score:\", round(roc_auc_score(y_eval, y_proba), 4))\n",
    "    print(\"\\n\")\n",
    "\n",
    "evaluate_model(rf_best, X_test, y_test, \"Random Forest\")\n",
    "evaluate_model(lr_best, X_test_scaled, y_test, \"Logistic Regression (scaled)\")\n",
    "evaluate_model(svm_best, X_test_scaled, y_test, \"SVM (RBF)\")\n",
    "evaluate_model(knn_best, X_test_scaled, y_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8c079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb88ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
